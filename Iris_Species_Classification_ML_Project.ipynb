{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Iris Species Classification\n",
        "\n",
        "\n",
        "*   Dataset Used - https://www.kaggle.com/datasets/arshid/iris-flower-dataset\n",
        "*   Python Modules Used - numpy, pandas, matplotlib\n",
        "*   Machine Learning Algorithms used - Logistic Regression\n",
        "*   Features of Species - \n",
        "  * Sepal Length (X[0])\n",
        "  * Sepal Width (X[1])\n",
        "  * Petal Length (X[2])\n",
        "  * Petal Width (X[3])\n",
        "\n",
        "*   Species (Target Variable Y) - \n",
        "  * Iris Setosa (Y = 0)\n",
        "  * Iris versicolor (Y = 1) \n",
        "  * Iris virginica (Y = 2)\n",
        "\n",
        "*   Train Test Split - 80/20\n",
        "*   Model Training\n",
        "*   Model Testing\n",
        "*   Give values and predict \n"
      ],
      "metadata": {
        "id": "_uFAtUkqqxEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FomWXLKsqq9V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flowers = pd.read_csv('IRIS.csv')\n",
        "flowers['species']"
      ],
      "metadata": {
        "id": "JwNBGDwoNQ_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e77fc6-0d48-414e-8aa6-25e1180eec42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         Iris-setosa\n",
              "1         Iris-setosa\n",
              "2         Iris-setosa\n",
              "3         Iris-setosa\n",
              "4         Iris-setosa\n",
              "            ...      \n",
              "145    Iris-virginica\n",
              "146    Iris-virginica\n",
              "147    Iris-virginica\n",
              "148    Iris-virginica\n",
              "149    Iris-virginica\n",
              "Name: species, Length: 150, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X =flowers.drop(columns=['species']).values\n",
        "y =flowers['species'].values"
      ],
      "metadata": {
        "id": "w0p-EasxT9i4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_split=0.2):\n",
        "  n = X.shape[0]\n",
        "  n_test = int(n * test_split)\n",
        "  test_indices = np.random.choice(range(n), n_test, replace=False)\n",
        "  train_indices = np.delete(range(n), test_indices)\n",
        "  X_train = np.array(X[train_indices])\n",
        "  X_test = np.array(X[test_indices])\n",
        "  y_train = np.array(y[train_indices])\n",
        "  y_test = np.array(y[test_indices])\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "0uXtGEGJUdR2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "metadata": {
        "id": "1Dxpg75FVFxV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate=0.0001, num_iterations=100):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iterations = num_iterations\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "\n",
        "  def grad_dw(self,x,y,w,b,alpha,N):\n",
        "    dw = (1 / N) * np.dot(x.T, (self.sigmoid(np.dot(x, w)+b) - y)) \n",
        "    return dw\n",
        "  \n",
        "  def grad_b(self,x,y,w,b, N):\n",
        "    db = (1 / N) * np.sum(self.sigmoid(np.dot(x, w)+b) - y, axis=0)\n",
        "    return db\n",
        "  \n",
        "  def hot_ones_encoding(self, y):\n",
        "      classes = np.unique(y)\n",
        "      # print(len(classes))\n",
        "      one_hot = np.zeros((y.shape[0], len(classes)))\n",
        "      for idx, label in enumerate(classes):\n",
        "          # print(idx, label)\n",
        "          # print(y == label)\n",
        "          one_hot[y == label, idx] = 1\n",
        "      # print(\"one\", one_hot)\n",
        "      return one_hot\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    samples = X.shape[0]\n",
        "    features = X.shape[1]\n",
        "    num_classes = np.unique(y).shape[0]\n",
        "    self.weights = np.zeros((features, num_classes))\n",
        "    self.bias = np.zeros((1,num_classes))\n",
        "    one_hot_y = self.hot_ones_encoding(y)\n",
        "    for i in range(self.num_iterations): \n",
        "      z = np.dot(X, self.weights) + self.bias\n",
        "      y_pred = self.sigmoid(z)\n",
        "\n",
        "      dw = self.grad_dw(X, one_hot_y, self.weights, self.bias, self.learning_rate, samples)\n",
        "      db = self.grad_b(X, one_hot_y, self.weights, self.bias, samples)\n",
        "\n",
        "      self.weights -= self.learning_rate*dw\n",
        "      self.bias -= self.learning_rate*db\n",
        "  \n",
        "  def predict(self, X):\n",
        "    z = np.dot(X, self.weights) + self.bias\n",
        "    y_pred = self.sigmoid(z)\n",
        "    # print(y_pred)\n",
        "    return np.argmax(y_pred, axis=1)\n"
      ],
      "metadata": {
        "id": "jsxgjK7bVN1l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_model = LogisticRegression(learning_rate = 0.1 , num_iterations= 10000)"
      ],
      "metadata": {
        "id": "feF39xnLeLp6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {0: \"Iris-setosa\", 1: \"Iris-versicolor\", 2:\"Iris-virginica\"}\n",
        "\n",
        "LR_model.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "wE9u2jLjfbJR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LR_model.predict(X_train)\n",
        "count = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if mapping[y_pred[i]] == y_train[i]:\n",
        "    count+= 1\n",
        "print(\"Train Accuracy = \", count * 100/ len(y_train))\n",
        "  \n",
        "y_pred = LR_model.predict(X_test)\n",
        "count = 0\n",
        "for i in range(len(y_pred)):\n",
        "  if mapping[y_pred[i]] == y_test[i]:\n",
        "    count+= 1\n",
        "print(\"Test Accuracy = \", count * 100/ len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "022xjg_NknSR",
        "outputId": "7156b7f1-6913-4501-fcfd-6505f4e8cc86"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy =  99.16666666666667\n",
            "Test Accuracy =  93.33333333333333\n"
          ]
        }
      ]
    }
  ]
}